print(prop)
str(PD)
# Summary function for variable predictors
description_0to1 <- function(x){
c(mean = mean(x, na.rm = TRUE),
sd = sd(x, na.rm = TRUE),
min = min(x, na.rm = TRUE),
max = max(x,na.rm = TRUE))
}
lapply(PD[c('A08', 'A22', 'A24', 'A25')], description_0to1)
summary(PD[c('A01', 'A04', 'A12', 'A17', 'A18', 'A23')])
PD_clean <- na.omit(PD)
dim(PD_clean)
library(corrplot)
corrplot(cor(PD_clean[1:25]), method = "number")
summary(PD_clean[c('A07', 'A13', 'A25')])
summary(PD_clean[c('A11', 'A21')])
attributes_to_drop <- c("A07", "A11", "A13", "A21", "A25")
PD_clean <- PD_clean[, !(names(PD_clean) %in% attributes_to_drop)]
remove_outliers <- function(data) {
# Calculate Q1 and Q3
Q1 <- apply(data, 2, quantile, probs = 0.25, na.rm = TRUE)
Q3 <- apply(data, 2, quantile, probs = 0.75, na.rm = TRUE)
# Calculate IQR
IQR <- Q3 - Q1
# Define upper and lower bounds for outliers
upper_bound <- Q3 + 1000 * IQR
lower_bound <- Q1 - 1000 * IQR
# Flag rows containing outliers
outlier_rows <- apply(data, 1, function(x) any(x < lower_bound | x > upper_bound, na.rm = TRUE))
# Remove rows with outliers
data_clean <- data[!outlier_rows, ]
return(data_clean)
}
PD_clean <- remove_outliers(PD_clean)
PD_clean
PD_clean
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
Phish <- read.csv("PhishingData.csv")
set.seed(31484808)
L <- as.data.frame(c(1:50))
L <- L[sample(nrow(L), 10, replace = FALSE),]
Phish <- Phish[(Phish$A01 %in% L),]
PD <- Phish[sample(nrow(Phish), 2000, replace = FALSE),] # sample of 2000 rows
head(PD)
counts <- table(PD$Class)
# Calculate the proportions of phishing and legitimate sites
prop <- prop.table(counts)
print(prop)
str(PD)
# Summary function for variable predictors
description_0to1 <- function(x){
c(mean = mean(x, na.rm = TRUE),
sd = sd(x, na.rm = TRUE),
min = min(x, na.rm = TRUE),
max = max(x,na.rm = TRUE))
}
lapply(PD[c('A08', 'A22', 'A24', 'A25')], description_0to1)
summary(PD[c('A01', 'A04', 'A12', 'A17', 'A18', 'A23')])
PD_clean <- na.omit(PD)
dim(PD_clean)
library(corrplot)
corrplot(cor(PD_clean[1:25]), method = "number")
summary(PD_clean[c('A07', 'A13', 'A25')])
summary(PD_clean[c('A11', 'A21')])
attributes_to_drop <- c("A07", "A11", "A13", "A21", "A25")
PD_clean <- PD_clean[, !(names(PD_clean) %in% attributes_to_drop)]
remove_outliers <- function(data) {
# Calculate Q1 and Q3
Q1 <- apply(data, 2, quantile, probs = 0.25, na.rm = TRUE)
Q3 <- apply(data, 2, quantile, probs = 0.75, na.rm = TRUE)
# Calculate IQR
IQR <- Q3 - Q1
# Define upper and lower bounds for outliers
upper_bound <- Q3 + 1.5 * IQR
lower_bound <- Q1 - 1.5 * IQR
# Flag rows containing outliers
outlier_rows <- apply(data, 1, function(x) any(x < lower_bound | x > upper_bound, na.rm = TRUE))
# Remove rows with outliers
data_clean <- data[!outlier_rows, ]
return(data_clean)
}
PD_clean <- remove_outliers(PD_clean)
PD_clean
# Remove outliers from A01
PD_clean <- subset(PD_clean, PD_clean$A01 > (Q1 - 1.5*IQR)
& PD_clean < (Q3 + 1.5*IQR))
Q1 <- quantile(PD_clean$A01, 0.25)
Q3 <- quantile(PD_clean$A01, 0.75)
IQR <- Q3 - Q1
# Remove outliers from A01
PD_clean <- subset(PD_clean, PD_clean$A01 > (Q1 - 1.5*IQR)
& PD_clean < (Q3 + 1.5*IQR))
PD_clean
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
Phish <- read.csv("PhishingData.csv")
set.seed(31484808)
L <- as.data.frame(c(1:50))
L <- L[sample(nrow(L), 10, replace = FALSE),]
Phish <- Phish[(Phish$A01 %in% L),]
PD <- Phish[sample(nrow(Phish), 2000, replace = FALSE),] # sample of 2000 rows
head(PD)
counts <- table(PD$Class)
# Calculate the proportions of phishing and legitimate sites
prop <- prop.table(counts)
print(prop)
str(PD)
# Summary function for variable predictors
description_0to1 <- function(x){
c(mean = mean(x, na.rm = TRUE),
sd = sd(x, na.rm = TRUE),
min = min(x, na.rm = TRUE),
max = max(x,na.rm = TRUE))
}
lapply(PD[c('A08', 'A22', 'A24', 'A25')], description_0to1)
summary(PD[c('A01', 'A04', 'A12', 'A17', 'A18', 'A23')])
PD_clean <- na.omit(PD)
dim(PD_clean)
library(corrplot)
corrplot(cor(PD_clean[1:25]), method = "number")
summary(PD_clean[c('A07', 'A13', 'A25')])
summary(PD_clean[c('A11', 'A21')])
attributes_to_drop <- c("A07", "A11", "A13", "A21", "A25")
PD_clean <- PD_clean[, !(names(PD_clean) %in% attributes_to_drop)]
PD_clean
Q1 <- quantile(PD_clean$A01, 0.25)
Q3 <- quantile(PD_clean$A01, 0.75)
IQR <- Q3 - Q1
# Remove outliers from A01
outliers <- subset(PD_clean, PD_clean$A01 > (Q1 - 1.5*IQR)
& PD_clean < (Q3 + 1.5*IQR))
outliers
# Remove outliers from A01
Q1
# Remove outliers from A01
IQR
# Remove outliers from A01
Q3
outliers <- PD_clean$A01[PD_clean$A01 < l_bound | PD_clean$A01 > u_bound]
Q1 <- quantile(PD_clean$A01, 0.25)
Q3 <- quantile(PD_clean$A01, 0.75)
IQR <- Q3 - Q1
# Remove outliers from A01
l_bound <- Q1 - 1.5*IQR
u_bound <- Q3 + 1.5*IQR
outliers <- PD_clean$A01[PD_clean$A01 < l_bound | PD_clean$A01 > u_bound]
outliers <- PD_clean$A01[PD_clean$A01 < l_bound | PD_clean$A01 > u_bound]
outliers
set.seed(31484808)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
install.packages("tree")
library(tree)
set.seed(31484808)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
library(tree)
ptfit = tree(class)
ptfit = tree(class~., data = PD_clean.train)
library(tree)
ptfit = tree(class~., data = PD_clean.train)
library(tree)
ptfit = tree(Class~., data = PD_clean.train)
ptfit
plot(ptfit)
text(ptfit, pretty = 0)
PD_clean.train
set.seed(31484808)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
library(tree)
ptfit = tree(Class~., data = PD_clean.train)
ptfit
library(tree)
ptfit = tree(Class~., data = PD_clean.train, method = "class")
ptfit
plot(ptfit)
text(ptfit, pretty = 0)
library(tree)
ptfit = tree(Class~., data = PD_clean.train, method = "class")
ptfit
plot(ptfit)
text(ptfit, pretty = 0)
PD_clean.test = PD_clean[-train.row,]
PD_clean.train
library(tree)
ptfit = tree(formula = Class~., data = PD_clean.train)
ptfit
plot(ptfit)
text(ptfit, pretty = 0)
library(tree)
c.fit = tree(formula = Class~., data = PD_clean.train)
c.fit
plot(ptfit)
text(ptfit, pretty = 0)
plot(c.fit)
text(c.fit, pretty = 0)
c.predict = predict(c.fit, c.test, type = "class")
c.predict = predict(c.fit, c.test)
library(tree)
c.fit = tree(formula = Class~ A1 , data = PD_clean.train)
library(tree)
c.fit = tree(formula = Class~ A01 , data = PD_clean.train)
c.fit
c.fit = tree(formula = Class~ A01 + A02 , data = PD_clean.train)
library(tree)
c.fit = tree(formula = Class~ A01 + A02 , data = PD_clean.train)
c.fit
c.fit = tree(formula = Class~ A01 + A02 + A03 + A04, data = PD_clean.train)
c.fit
plot(c.fit)
text(c.fit, pretty = 0)
library(tree)
c.fit = tree(formula = Class~ A01 + A02 + A03 + A04, data = PD_clean.train)
c.fit
plot(c.fit)
text(c.fit, pretty = 0)
library(tree)
c.fit = tree(formula = Class~ A01 + A02 + A03 + A04 + A05, data = PD_clean.train)
c.fit
plot(c.fit)
text(c.fit, pretty = 0)
c.fit
library(tree)
c.fit = tree(formula = Class~ A01 + A02 + A03 + A04 + A05 + A06 + A08, data = PD_clean.train)
c.fit
library(tree)
c.fit = tree(formula = Class~ A01 + A02 + A03 + A04 + A05 + A06 + A08, data = PD_clean.train)
c.fit
plot(c.fit)
text(c.fit, pretty = 0)
c.fit = tree(formula = Class~ ., data = PD_clean.train)
c.fit
plot(c.fit)
text(c.fit, pretty = 0)
PD_clean$Class <- as.factor(PD_clean$Class)
c.fit = tree(formula = Class~ ., data = PD_clean.train)
c.fit
plot(c.fit)
text(c.fit, pretty = 0)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
Phish <- read.csv("PhishingData.csv")
set.seed(31484808)
L <- as.data.frame(c(1:50))
L <- L[sample(nrow(L), 10, replace = FALSE),]
Phish <- Phish[(Phish$A01 %in% L),]
PD <- Phish[sample(nrow(Phish), 2000, replace = FALSE),] # sample of 2000 rows
head(PD)
counts <- table(PD$Class)
# Calculate the proportions of phishing and legitimate sites
prop <- prop.table(counts)
print(prop)
str(PD)
# Summary function for variable predictors
description_0to1 <- function(x){
c(mean = mean(x, na.rm = TRUE),
sd = sd(x, na.rm = TRUE),
min = min(x, na.rm = TRUE),
max = max(x,na.rm = TRUE))
}
lapply(PD[c('A08', 'A22', 'A24', 'A25')], description_0to1)
summary(PD[c('A01', 'A04', 'A12', 'A17', 'A18', 'A23')])
PD_clean <- na.omit(PD)
dim(PD_clean)
library(corrplot)
corrplot(cor(PD_clean[1:25]), method = "number")
summary(PD_clean[c('A07', 'A13', 'A25')])
summary(PD_clean[c('A11', 'A21')])
attributes_to_drop <- c("A07", "A11", "A13", "A21", "A25")
PD_clean <- PD_clean[, !(names(PD_clean) %in% attributes_to_drop)]
PD_clean
set.seed(31484808)
PD_clean$Class <- as.factor(PD_clean$Class)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
PD_clean.train
library(tree)
c.fit = tree(formula = Class~ ., data = PD_clean.train)
c.fit
plot(c.fit)
text(c.fit, pretty = 0)
plot(c.fit)
text(c.fit, pretty = 0)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
Phish <- read.csv("PhishingData.csv")
set.seed(31484808)
L <- as.data.frame(c(1:50))
L <- L[sample(nrow(L), 10, replace = FALSE),]
Phish <- Phish[(Phish$A01 %in% L),]
PD <- Phish[sample(nrow(Phish), 2000, replace = FALSE),] # sample of 2000 rows
head(PD)
counts <- table(PD$Class)
# Calculate the proportions of phishing and legitimate sites
prop <- prop.table(counts)
print(prop)
str(PD)
# Summary function for variable predictors
description_0to1 <- function(x){
c(mean = mean(x, na.rm = TRUE),
sd = sd(x, na.rm = TRUE),
min = min(x, na.rm = TRUE),
max = max(x,na.rm = TRUE))
}
lapply(PD[c('A08', 'A22', 'A24', 'A25')], description_0to1)
summary(PD[c('A01', 'A04', 'A12', 'A17', 'A18', 'A23')])
summary(PD[c('A02', 'A03', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21')])
table(PD[c('A02', 'A03', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21')])
PD[c('A02', 'A03', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21')]
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
Phish <- read.csv("PhishingData.csv")
set.seed(31484808)
L <- as.data.frame(c(1:50))
L <- L[sample(nrow(L), 10, replace = FALSE),]
Phish <- Phish[(Phish$A01 %in% L),]
PD <- Phish[sample(nrow(Phish), 2000, replace = FALSE),] # sample of 2000 rows
head(PD)
counts <- table(PD$Class)
# Calculate the proportions of phishing and legitimate sites
prop <- prop.table(counts)
print(prop)
str(PD)
# Summary function for variable predictors
description_0to1 <- function(x){
c(mean = mean(x, na.rm = TRUE),
sd = sd(x, na.rm = TRUE),
min = min(x, na.rm = TRUE),
max = max(x,na.rm = TRUE))
}
lapply(PD[c('A08', 'A22', 'A24', 'A25')], description_0to1)
summary(PD[c('A01', 'A04', 'A12', 'A17', 'A18', 'A23')])
PD[c('A02', 'A03', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21')]
summary(PD_clean[c('A11', 'A21')])
PD_clean <- na.omit(PD)
dim(PD_clean)
library(corrplot)
corrplot(cor(PD_clean[1:25]), method = "number")
summary(PD_clean[c('A07', 'A13', 'A25')])
summary(PD_clean[c('A11', 'A21')])
attributes_to_drop <- c("A13", "A21", "A25")
PD_clean <- PD_clean[, !(names(PD_clean) %in% attributes_to_drop)]
PD_clean
summary(PD[c('A02', 'A03', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21')])
summary(PD[c('A02', 'A03', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21')])
attributes_to_drop <- c("A13", "A21", "A25")
PD_clean <- PD_clean[, !(names(PD_clean) %in% attributes_to_drop)]
set.seed(31484808)
PD_clean$Class <- as.factor(PD_clean$Class)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
PD_clean.train
library(tree)
c.fit = tree(formula = Class~ ., data = PD_clean.train)
c.fit
plot(c.fit)
text(c.fit, pretty = 0)
set.seed(31484808)
PD_clean$Class <- as.factor(PD_clean$Class)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
c.fit = tree(formula = Class~ A01, data = PD_clean.train)
c.fit
c.fit = tree(formula = Class~ A01 + A02, data = PD_clean.train)
c.fit
set.seed(31484808)
PD_clean$Class <- as.factor(PD_clean$Class)
PD_clean$A02 <- as.factor(PD_clean$A02)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
library(tree)
c.fit = tree(formula = Class~ A01 + A02, data = PD_clean.train)
c.fit
set.seed(31484808)
PD_clean$Class <- as.factor(PD_clean$Class)
PD_clean$A02 <- as.factor(PD_clean$A02)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
library(tree)
c.fit = tree(formula = Class~ A01 + A02, data = PD_clean.train)
c.fit
library(tree)
c.fit = tree(formula = Class~ A01 + A02 + A03, data = PD_clean.train)
c.fit
library(tree)
c.fit = tree(formula = Class~ ., data = PD_clean.train)
c.fit
summary(c.fit)
plot(c.fit)
text(c.fit, pretty = 0)
library(tree)
dt.fit = tree(formula = Class~ ., data = PD_clean.train)
summary(dt.fit)
plot(dt.fit)
text(dt.fit, pretty = 0)
library(tree)
dt.fit = tree(formula = Class~ A01 + A23+ A18, data = PD_clean.train)
summary(dt.fit)
plot(dt.fit)
text(dt.fit, pretty = 0)
library(tree)
dt.fit = tree(formula = Class~ ., data = PD_clean.train)
summary(dt.fit)
plot(dt.fit)
text(dt.fit, pretty = 0)
hi <- PD_clean
hi <- PD_clean
hi <- as.factor(hi)
set.seed(31484808)
PD_clean$Class <- as.factor(PD_clean$Class)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
library(tree)
dt.fit = tree(formula = Class~ ., data = PD_clean.train)
summary(dt.fit)
plot(dt.fit)
text(dt.fit, pretty = 0)
ipredict <- predict(dt.fit,PD_clean.test, type = "class" )
ipredict <- predict(dt.fit,PD_clean.test, type = "class" )
table(observed = PD_clean$Class, predicted = ipredict)
ipredict <- predict(dt.fit,PD_clean.test, type = "class" )
#table(observed = PD_clean$Class, predicted = ipredict)
ipredict <- predict(dt.fit,PD_clean.test, type = "class" )
table(observed = PD_clean.test$Class, predicted = ipredict)
install.packages("e1071")
library(e1071)
nb_model <- naiveBayes(Class~ ., data = PD_clean.train)
nb_predict = predict(nb_model, PD_clean.test)
nb_predict
table(actual = PD_clean.test$Class, predicted = nb_predict)
table(actual = PD_clean.test$Class, predicted = nb_predict)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
Phish <- read.csv("PhishingData.csv")
set.seed(31484808)
L <- as.data.frame(c(1:50))
L <- L[sample(nrow(L), 10, replace = FALSE),]
Phish <- Phish[(Phish$A01 %in% L),]
PD <- Phish[sample(nrow(Phish), 2000, replace = FALSE),] # sample of 2000 rows
head(PD)
counts <- table(PD$Class)
# Calculate the proportions of phishing and legitimate sites
prop <- prop.table(counts)
print(prop)
str(PD)
# Summary function for variable predictors
description_0to1 <- function(x){
c(mean = mean(x, na.rm = TRUE),
sd = sd(x, na.rm = TRUE),
min = min(x, na.rm = TRUE),
max = max(x,na.rm = TRUE))
}
lapply(PD[c('A08', 'A22', 'A24', 'A25')], description_0to1)
summary(PD[c('A01', 'A04', 'A12', 'A17', 'A18', 'A23')])
summary(PD[c('A02', 'A03', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21')])
PD_clean <- na.omit(PD)
dim(PD_clean)
library(corrplot)
corrplot(cor(PD_clean[1:25]), method = "number")
summary(PD_clean[c('A07', 'A13', 'A25')])
summary(PD_clean[c('A11', 'A21')])
attributes_to_drop <- c("A13", "A21", "A25")
PD_clean <- PD_clean[, !(names(PD_clean) %in% attributes_to_drop)]
set.seed(31484808)
PD_clean$Class <- as.factor(PD_clean$Class)
train.row = sample(1:nrow(PD_clean), 0.7*nrow(PD_clean))
PD_clean.train = PD_clean[train.row,]
PD_clean.test = PD_clean[-train.row,]
library(tree)
dt.fit = tree(formula = Class~ ., data = PD_clean.train)
summary(dt.fit)
plot(dt.fit)
text(dt.fit, pretty = 0)
ipredict <- predict(dt.fit,PD_clean.test, type = "class" )
table(observed = PD_clean.test$Class, predicted = ipredict)
library(e1071)
nb_model <- naiveBayes(Class~ ., data = PD_clean.train)
library(e1071)
nb_model <- naiveBayes(Class~ ., data = PD_clean.train)
nb_predict = predict(nb_model, PD_clean.test)
table(actual = PD_clean.test$Class, predicted = nb_predict)
nb_predict = predict(nb_model, PD_clean.test)
table(actual = PD_clean.test$Class, predicted = nb_predict)
nb_predict = predict(nb_model, PD_clean.test, type = 'raw')
table(actual = PD_clean.test$Class, predicted = nb_predict)
nb_predict = predict(nb_model, PD_clean.test)
table(actual = PD_clean.test$Class, predicted = nb_predict)
nb_predict = predict(nb_model, PD_clean.test)
table(actual = PD_clean.test$Class, predicted = nb_predict)
nb_predict = predict(nb_model, PD_clean.test, type = 'Class')
nb_predict = predict(nb_model, PD_clean.test, type = 'class')
table(actual = PD_clean.test$Class, predicted = nb_predict)
library(e1071)
nb_model <- naiveBayes(Class~ ., data = PD_clean.train)
nb_predict = predict(nb_model, PD_clean.test, type = 'class')
table(actual = PD_clean.test$Class, predicted = nb_predict)
install.packages("adabag")
install.packages("adabag")
install.packages("adabag")
install.packages("adabag")
